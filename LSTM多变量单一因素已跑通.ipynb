{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写在前面， \n",
    "1. numpy 用这个版本 numpy-1.19.5， 20.x会报错\n",
    "2. split_sequences # 构造多元监督学习型数据 这个函数 不要对它的名字所蒙蔽，看不懂可以不看， 在你看完硕士女+博士男的配对后，就明白他的功能了。\n",
    "3. 数据归一化标准化处理都是障眼法，这段代码有助于你理解lstm的本质。\n",
    "4. 完全看懂这个，再把归一化，反归一化放进来即可。\n",
    "-----------------------------------------------\n",
    "拔高：\n",
    "5. 当你完成看懂这段代码后，再来尝试回答这个问题：  过去m天 n个特征 决定今天的q个特征 这如何重构数据集， 也就是split_sequences 高度抽象的代码 还不是那么好写，虽然很短的不几行。 \n",
    "决定今天的q 个特征， 所以喽 # 输出一个数字 所以就写死了 1  model.add(Dense(1)) 这里就是q了 而不是1啦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必备库\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造多元监督学习型数据\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# 获取待预测数据的位置\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# 如果待预测数据超过序列长度，构造完成\n",
    "\t\tif end_ix > len(sequences)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# 取前n_steps行数据的前5列作为输入X，第n_step行数据的最后一列作为输出y\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :5], sequences[end_ix, 5:]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义序列，构建数据\n",
    "in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = array([11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
    "in_seq3 = array([12, 22, 32, 42, 52, 62, 72, 82, 92])\n",
    "in_seq4 = array([13, 23, 33, 43, 53, 63, 73, 83, 93])\n",
    "in_seq5 = array([14, 24, 34, 44, 54, 64, 74, 84, 94])\n",
    "out_seq = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "in_seq4 = in_seq4.reshape((len(in_seq4), 1))\n",
    "in_seq5 = in_seq5.reshape((len(in_seq5), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, in_seq3,in_seq4,in_seq5,out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11, 12, 13, 14, 15],\n",
       "       [20, 21, 22, 23, 24, 25],\n",
       "       [30, 31, 32, 33, 34, 35],\n",
       "       [40, 41, 42, 43, 44, 45],\n",
       "       [50, 51, 52, 53, 54, 55],\n",
       "       [60, 61, 62, 63, 64, 65],\n",
       "       [70, 71, 72, 73, 74, 75],\n",
       "       [80, 81, 82, 83, 84, 85],\n",
       "       [90, 91, 92, 93, 94, 95]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 到这里就构建好了，dataset和你的csv是一样的，对不对 10, 11, 12, 13, 14->25    20, 21, 22, 23, 24->35 ...\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape  \n",
    "# 9行6列的矩阵， 要记住这个形状， 9行6列， 因为下面我会提问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你的csv表 0-4是特征，5是预测值， 但要注意的是 第一行的0-4，预测的是第二行的5。 第二行的0-4 预测第三行的5\n",
    "# 也就是说 10, 11, 12, 13, 14--》25  20, 21, 22, 23, 24-》35....\n",
    "# 所以喽，所谓的# 构造多元监督学习型数据split_sequences 这个函数，就是为了完成这个回归任务的分割，  10, 11, 12, 13, 14--》25  20, 21, 22, 23, 24-》35.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a number of time steps\n",
    "# 设置时间序列步长， 因为定义的是 昨天4特征预测今天1特征 所以就是 1啦， 同理可以是2，3，4.\n",
    "n_steps = 1\n",
    "# 输入数据形状X(9,1,5), 9组数据，每组1个时间步，每个时间步5个特征,y(8,1)，8组数据，每组1个特征值：\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "# 定义特征值，直接利用X(6,3,3)中的第3位(特征值)赋值即可\n",
    "n_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 1, 5), (8, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape\n",
    "# 等等，为什么变成 8行了， 这是时间序列预测的特点， 用过去一天的5个特征预测今天的1个特征。\n",
    "# 也就是说 决定第一行的最后一列的5个特征是缺失的，而最后一行的5个特征啥也决定不了。\n",
    "# 你也可以这样理解，本科女找硕士男， 硕士女找博士男  所以博士女和本科男就都是光棍。  \n",
    "# 这时候再回看这个函数， 构造多元监督学习型数据 def split_sequences(sequences, n_steps): 你就明白他的作用了， 因为现在 dataset是 本科男女， 硕士男女，博士男女 占成一排排，他不能做lstm预测\n",
    "# 经过这个函数， 就成了 本科女找硕士男， 硕士女找博士男  长度也有原来的 3行变成了2行。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 输入 n_steps = 1 （前一天）,  n_features = 5 (5 特征)\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "# 输出一个数字 所以就写死了 1 \n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 - 3s - loss: 4041.9963 - val_loss: 3973.7622\n",
      "Epoch 2/100\n",
      "4/4 - 0s - loss: 3883.2280 - val_loss: 3807.4819\n",
      "Epoch 3/100\n",
      "4/4 - 0s - loss: 3688.6443 - val_loss: 3583.7666\n",
      "Epoch 4/100\n",
      "4/4 - 0s - loss: 3408.9253 - val_loss: 3255.7119\n",
      "Epoch 5/100\n",
      "4/4 - 0s - loss: 2997.4995 - val_loss: 2772.3911\n",
      "Epoch 6/100\n",
      "4/4 - 0s - loss: 2424.9377 - val_loss: 2125.5610\n",
      "Epoch 7/100\n",
      "4/4 - 0s - loss: 1701.9570 - val_loss: 1343.5026\n",
      "Epoch 8/100\n",
      "4/4 - 0s - loss: 888.9503 - val_loss: 539.2888\n",
      "Epoch 9/100\n",
      "4/4 - 0s - loss: 261.7368 - val_loss: 100.0602\n",
      "Epoch 10/100\n",
      "4/4 - 0s - loss: 160.7822 - val_loss: 162.1177\n",
      "Epoch 11/100\n",
      "4/4 - 0s - loss: 234.6162 - val_loss: 214.0104\n",
      "Epoch 12/100\n",
      "4/4 - 0s - loss: 174.3830 - val_loss: 137.9758\n",
      "Epoch 13/100\n",
      "4/4 - 0s - loss: 85.1178 - val_loss: 70.2100\n",
      "Epoch 14/100\n",
      "4/4 - 0s - loss: 48.2061 - val_loss: 52.0884\n",
      "Epoch 15/100\n",
      "4/4 - 0s - loss: 51.6742 - val_loss: 53.1922\n",
      "Epoch 16/100\n",
      "4/4 - 0s - loss: 52.0249 - val_loss: 38.4634\n",
      "Epoch 17/100\n",
      "4/4 - 0s - loss: 52.6422 - val_loss: 36.8080\n",
      "Epoch 18/100\n",
      "4/4 - 0s - loss: 29.4898 - val_loss: 28.8486\n",
      "Epoch 19/100\n",
      "4/4 - 0s - loss: 28.8494 - val_loss: 23.1454\n",
      "Epoch 20/100\n",
      "4/4 - 0s - loss: 25.1741 - val_loss: 18.3744\n",
      "Epoch 21/100\n",
      "4/4 - 0s - loss: 17.1206 - val_loss: 14.9138\n",
      "Epoch 22/100\n",
      "4/4 - 0s - loss: 14.8346 - val_loss: 12.1102\n",
      "Epoch 23/100\n",
      "4/4 - 0s - loss: 13.0101 - val_loss: 10.2220\n",
      "Epoch 24/100\n",
      "4/4 - 0s - loss: 10.3741 - val_loss: 8.9066\n",
      "Epoch 25/100\n",
      "4/4 - 0s - loss: 8.8938 - val_loss: 7.3208\n",
      "Epoch 26/100\n",
      "4/4 - 0s - loss: 7.8539 - val_loss: 6.3962\n",
      "Epoch 27/100\n",
      "4/4 - 0s - loss: 6.5982 - val_loss: 5.8635\n",
      "Epoch 28/100\n",
      "4/4 - 0s - loss: 5.8536 - val_loss: 5.0810\n",
      "Epoch 29/100\n",
      "4/4 - 0s - loss: 5.3805 - val_loss: 4.5862\n",
      "Epoch 30/100\n",
      "4/4 - 0s - loss: 4.7048 - val_loss: 4.2044\n",
      "Epoch 31/100\n",
      "4/4 - 0s - loss: 4.2351 - val_loss: 3.8048\n",
      "Epoch 32/100\n",
      "4/4 - 0s - loss: 3.8597 - val_loss: 3.4635\n",
      "Epoch 33/100\n",
      "4/4 - 0s - loss: 3.5479 - val_loss: 3.1806\n",
      "Epoch 34/100\n",
      "4/4 - 0s - loss: 3.2277 - val_loss: 2.9421\n",
      "Epoch 35/100\n",
      "4/4 - 0s - loss: 2.9743 - val_loss: 2.7138\n",
      "Epoch 36/100\n",
      "4/4 - 0s - loss: 2.7514 - val_loss: 2.5059\n",
      "Epoch 37/100\n",
      "4/4 - 0s - loss: 2.5501 - val_loss: 2.3256\n",
      "Epoch 38/100\n",
      "4/4 - 0s - loss: 2.3613 - val_loss: 2.1657\n",
      "Epoch 39/100\n",
      "4/4 - 0s - loss: 2.1957 - val_loss: 2.0215\n",
      "Epoch 40/100\n",
      "4/4 - 0s - loss: 2.0491 - val_loss: 1.8897\n",
      "Epoch 41/100\n",
      "4/4 - 0s - loss: 1.9179 - val_loss: 1.7731\n",
      "Epoch 42/100\n",
      "4/4 - 0s - loss: 1.7992 - val_loss: 1.6688\n",
      "Epoch 43/100\n",
      "4/4 - 0s - loss: 1.6919 - val_loss: 1.5749\n",
      "Epoch 44/100\n",
      "4/4 - 0s - loss: 1.5960 - val_loss: 1.4896\n",
      "Epoch 45/100\n",
      "4/4 - 0s - loss: 1.5098 - val_loss: 1.4125\n",
      "Epoch 46/100\n",
      "4/4 - 0s - loss: 1.4319 - val_loss: 1.3427\n",
      "Epoch 47/100\n",
      "4/4 - 0s - loss: 1.3611 - val_loss: 1.2792\n",
      "Epoch 48/100\n",
      "4/4 - 0s - loss: 1.2968 - val_loss: 1.2212\n",
      "Epoch 49/100\n",
      "4/4 - 0s - loss: 1.2381 - val_loss: 1.1680\n",
      "Epoch 50/100\n",
      "4/4 - 0s - loss: 1.1844 - val_loss: 1.1191\n",
      "Epoch 51/100\n",
      "4/4 - 0s - loss: 1.1351 - val_loss: 1.0740\n",
      "Epoch 52/100\n",
      "4/4 - 0s - loss: 1.0896 - val_loss: 1.0321\n",
      "Epoch 53/100\n",
      "4/4 - 0s - loss: 1.0473 - val_loss: 0.9931\n",
      "Epoch 54/100\n",
      "4/4 - 0s - loss: 1.0080 - val_loss: 0.9567\n",
      "Epoch 55/100\n",
      "4/4 - 0s - loss: 0.9713 - val_loss: 0.9225\n",
      "Epoch 56/100\n",
      "4/4 - 0s - loss: 0.9369 - val_loss: 0.8902\n",
      "Epoch 57/100\n",
      "4/4 - 0s - loss: 0.9044 - val_loss: 0.8596\n",
      "Epoch 58/100\n",
      "4/4 - 0s - loss: 0.8736 - val_loss: 0.8306\n",
      "Epoch 59/100\n",
      "4/4 - 0s - loss: 0.8444 - val_loss: 0.8029\n",
      "Epoch 60/100\n",
      "4/4 - 0s - loss: 0.8165 - val_loss: 0.7764\n",
      "Epoch 61/100\n",
      "4/4 - 0s - loss: 0.7898 - val_loss: 0.7509\n",
      "Epoch 62/100\n",
      "4/4 - 0s - loss: 0.7642 - val_loss: 0.7265\n",
      "Epoch 63/100\n",
      "4/4 - 0s - loss: 0.7396 - val_loss: 0.7028\n",
      "Epoch 64/100\n",
      "4/4 - 0s - loss: 0.7159 - val_loss: 0.6800\n",
      "Epoch 65/100\n",
      "4/4 - 0s - loss: 0.6930 - val_loss: 0.6579\n",
      "Epoch 66/100\n",
      "4/4 - 0s - loss: 0.6708 - val_loss: 0.6364\n",
      "Epoch 67/100\n",
      "4/4 - 0s - loss: 0.6493 - val_loss: 0.6156\n",
      "Epoch 68/100\n",
      "4/4 - 0s - loss: 0.6284 - val_loss: 0.5953\n",
      "Epoch 69/100\n",
      "4/4 - 0s - loss: 0.6082 - val_loss: 0.5756\n",
      "Epoch 70/100\n",
      "4/4 - 0s - loss: 0.5885 - val_loss: 0.5565\n",
      "Epoch 71/100\n",
      "4/4 - 0s - loss: 0.5694 - val_loss: 0.5378\n",
      "Epoch 72/100\n",
      "4/4 - 0s - loss: 0.5508 - val_loss: 0.5197\n",
      "Epoch 73/100\n",
      "4/4 - 0s - loss: 0.5327 - val_loss: 0.5021\n",
      "Epoch 74/100\n",
      "4/4 - 0s - loss: 0.5152 - val_loss: 0.4849\n",
      "Epoch 75/100\n",
      "4/4 - 0s - loss: 0.4982 - val_loss: 0.4683\n",
      "Epoch 76/100\n",
      "4/4 - 0s - loss: 0.4816 - val_loss: 0.4521\n",
      "Epoch 77/100\n",
      "4/4 - 0s - loss: 0.4656 - val_loss: 0.4364\n",
      "Epoch 78/100\n",
      "4/4 - 0s - loss: 0.4500 - val_loss: 0.4212\n",
      "Epoch 79/100\n",
      "4/4 - 0s - loss: 0.4349 - val_loss: 0.4064\n",
      "Epoch 80/100\n",
      "4/4 - 0s - loss: 0.4203 - val_loss: 0.3921\n",
      "Epoch 81/100\n",
      "4/4 - 0s - loss: 0.4061 - val_loss: 0.3783\n",
      "Epoch 82/100\n",
      "4/4 - 0s - loss: 0.3923 - val_loss: 0.3649\n",
      "Epoch 83/100\n",
      "4/4 - 0s - loss: 0.3790 - val_loss: 0.3520\n",
      "Epoch 84/100\n",
      "4/4 - 0s - loss: 0.3661 - val_loss: 0.3394\n",
      "Epoch 85/100\n",
      "4/4 - 0s - loss: 0.3535 - val_loss: 0.3273\n",
      "Epoch 86/100\n",
      "4/4 - 0s - loss: 0.3414 - val_loss: 0.3156\n",
      "Epoch 87/100\n",
      "4/4 - 0s - loss: 0.3296 - val_loss: 0.3042\n",
      "Epoch 88/100\n",
      "4/4 - 0s - loss: 0.3182 - val_loss: 0.2933\n",
      "Epoch 89/100\n",
      "4/4 - 0s - loss: 0.3070 - val_loss: 0.2826\n",
      "Epoch 90/100\n",
      "4/4 - 0s - loss: 0.2963 - val_loss: 0.2724\n",
      "Epoch 91/100\n",
      "4/4 - 0s - loss: 0.2858 - val_loss: 0.2624\n",
      "Epoch 92/100\n",
      "4/4 - 0s - loss: 0.2756 - val_loss: 0.2528\n",
      "Epoch 93/100\n",
      "4/4 - 0s - loss: 0.2657 - val_loss: 0.2434\n",
      "Epoch 94/100\n",
      "4/4 - 0s - loss: 0.2561 - val_loss: 0.2344\n",
      "Epoch 95/100\n",
      "4/4 - 0s - loss: 0.2468 - val_loss: 0.2256\n",
      "Epoch 96/100\n",
      "4/4 - 0s - loss: 0.2377 - val_loss: 0.2172\n",
      "Epoch 97/100\n",
      "4/4 - 0s - loss: 0.2289 - val_loss: 0.2089\n",
      "Epoch 98/100\n",
      "4/4 - 0s - loss: 0.2204 - val_loss: 0.2010\n",
      "Epoch 99/100\n",
      "4/4 - 0s - loss: 0.2121 - val_loss: 0.1933\n",
      "Epoch 100/100\n",
      "4/4 - 0s - loss: 0.2041 - val_loss: 0.1859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e8b11be0d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 到这里 你就搞清楚了，lstm的所谓时间序列的含义， 在股票预测的角度，就是过去决定现在，  过去m天 n个特征 决定今天的q 个特征， 就可以构建回归配对的任务来做了啊（本质就是硕士女，博士男的配对。。。）。\n",
    "# validation_data=(X, y) 还是用的训练集，偷懒而已\n",
    "model.fit(X, y, epochs=100, batch_size=2, verbose=2, validation_data=(X, y),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[116.49751]]\n"
     ]
    }
   ],
   "source": [
    "# 构建一个序列输入特征， 他们的y应该回归成115 对不对。\n",
    "x_input = array([100, 101, 102, 103, 104])  \n",
    "\n",
    "x_input = x_input.reshape((1, n_steps, n_features))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116.49751281738281"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 116 也可以了啊 和115差不多啊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
